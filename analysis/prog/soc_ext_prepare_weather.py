# -*- coding: utf-8 -*-
"""
Created on Mon Sep 16 11:25:50 2019

@author: Fabel

Steps:

     1) read in the time series for all of the variables and generate a wide
     version, i.e. a panel on the monitor-day level

     2) use the monitors, which are present at all of the observed years and which
     observe all the weather variables at the same time (see comment below) and
     find with QGIS the nearest associated weather monitor to each stadium.
     use that as input to restrict the wide weather df to the relevant monitors.
     -> exported as weather_prepare to Dropbox
"""

# packages
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.style as style


# paths work
#weather_source = 'F:/econ/soc_ext/analysis/data/source/weather/cdc_download_2019-08-28_11-40/data/'
#weather_output_Dx = 'C:/Users/fabel/Dropbox/soc_ext_Dx/analysis/data/intermediate/weather/'
#weather_output = 'F:/econ/soc_ext/analysis/data/intermediate/weather/'
#map_stadium_weather_monitor_input = 'C:/Users/fabel/Dropbox/soc_ext_Dx/analysis/data/intermediate/maps/' # comes as output from QGIS, generated by "Distance to nearest hub"


# HOME directories
weather_output_Dx = '/Users/marcfabel/Dropbox/soc_ext_Dx/analysis/data/intermediate/weather/'
map_stadium_weather_monitor_input = '/Users/marcfabel/Dropbox/soc_ext_Dx/analysis/data/intermediate/maps/' # comes as output from QGIS, generated by "Distance to nearest hub"
soccer_output = '/Users/marcfabel/Dropbox/soc_ext_Dx/analysis/data/intermediate/soccer/'




# magic numbers
first_year_wave = 2011
last_year_wave = 2015



###############################################################################
#       1)    Read in and merge the data
###############################################################################

# generate empty lists -> used to construct df that contains # of monitors for each var
lst_var = []
lst_number_monitors = []

j = 1
for var in ['TMK', 'TXK', 'TNK', 'TGK', 'VPM', 'NM', 'PM', 'UPM', 'RS', 'SDK', 'SH', 'FM']: #
     print(var)
     data = pd.read_csv(weather_source + 'data_' + var + '.csv', sep=',', encoding = 'UTF-8')
     data.drop(['Produkt_Code','Qualitaet_Niveau', 'Qualitaet_Byte'], axis=1, inplace=True)
     data.rename(columns={'Zeitstempel':'date'}, inplace=True)
     data['year'] = pd.to_numeric(data['date'].astype(str).str.slice(0,4))
     delete_rows = data[ (data['year']<first_year_wave) | (data['year']>last_year_wave) ].index
     data.drop(delete_rows, inplace=True)
     data.drop('year', axis=1, inplace=True)
     data.rename(columns={'Wert':var}, inplace=True)

     sdo = pd.read_csv(weather_source + 'sdo_' + var + '.csv', sep=',', encoding = 'UTF-8')
     sdo.drop(['Metadata_Link', 'Hoehe_ueber_NN'], axis=1, inplace=True)
     sdo.rename(columns={'Geogr_Laenge':'geo_x', 'Geogr_Breite':'geo_y'}, inplace=True)

     lst_var.append(var)
     lst_number_monitors.append(len(sdo))

     # merge data and sdo together
     data = data.merge(sdo, on=['SDO_ID'])

     # put together final data set
     if j == 1:
          weather = data
          j = j + 1
     else:
          weather = weather.merge(data, on=['SDO_ID', 'SDO_Name', 'geo_x', 'geo_y', 'date'], how='inner')

          # comment: maybe inner merge to have only keys that are present in all of the data frames?

dictionary = {'variable': lst_var, 'number_monitors': lst_number_monitors}
df_number_monitors = pd.DataFrame(dictionary)



###############################################################################
#       2 ) Weather monitors & their distance to stadiums
###############################################################################

monitors = weather.drop_duplicates(subset='SDO_ID')
monitors = monitors[['SDO_ID', 'date', 'SDO_Name', 'geo_x', 'geo_y']].copy()

# drop monitors which are not present over the entire period:
delete_rows = monitors[ (monitors['date'] != 20110101) ].index
monitors.drop(delete_rows, inplace=True)
monitors['D_all_years'] = 1

# read out
monitors.to_csv(weather_output_Dx + 'weather_monitors_coordinates_inner_merge.csv', sep=';', encoding='UTF-8')


# now go to QGIS and look for the nearest stadium-monitor pair and use only subset of monotors for output
# has to create     map_stadium_nearest_weather_monitor.csv'

# open up edited stadium-monitor pair
stadium_monitor = pd.read_csv(map_stadium_weather_monitor_input + 'map_stadium_nearest_weather_monitor.csv', sep=';', encoding = 'UTF-8')
stadium_monitor.drop(['field_1', 'Koordinaten_Nord', 'Koordinaten_Ost', 'PLZ', 'Stra√üe', 'Hausnummer', 'games_played'], axis=1, inplace=True)
stadium_monitor.rename(columns={'HubName':'SDO_ID', 'HubDist':'distance_closest_sdo'}, inplace=True)


# merge with weather data (inner)
weather = weather.merge(stadium_monitor, on=['SDO_ID'], how='inner')

# sort & order
weather = weather[[
     'date', 'stadium', 'Ort', 'SDO_ID', 'SDO_Name',
     'TMK', 'TXK', 'TNK', 'TGK', 'VPM', 'NM', 'PM', 'UPM', 'RS', 'SDK', 'SH', 'FM',
     'distance_closest_sdo', 'geo_x', 'geo_y']]

weather.sort_values(['Ort','date'], inplace=True)

# drop variables
weather.drop(['geo_x', 'geo_y'], axis=1, inplace=True)

# read out
weather.to_csv(weather_output_Dx + 'weather_prepared.csv', sep=';', encoding='UTF-8')



###############################################################################
#       3) Plotting distance of weather monitors to stadiums
###############################################################################



style.available
style.use('seaborn-darkgrid')

#style.use('seaborn-paper') # alternative talk and presentation - makes it bigger
#sns.set_context('paper')


# histogram unweighted
sns.distplot(stadium_monitor['distance_closest_sdo'], hist=True, kde=False, norm_hist=False,
             bins=int(50/4), color = 'darkblue',
             hist_kws={'edgecolor':'black'})

plt.xlabel('Distance [km]')
plt.ylabel('Count') # 'Number of monitor-stadium pairs'



###############################################################################
#           END OF FILE
###############################################################################



# to do: what shall I do with NANs in the columns

# Comments:
# - first I use the subset of monitors that have all the variables over all years
#    at a later robustness check, one could refine that approach: i.e. what is per
#    variable the closest monitor, have a weather_variable-specific stadium-monitor
#    match








# OLD:
# 1) Plotting
# other approach
#bins = np.arange(0,50,4)
#hist, edges = np.histogram(stadium_monitor['distance_closest_sdo'], bins)
#freq = hist/float(hist.sum())
#plt.bar(bins[:-1], freq, width=4, align="edge", ec="k" )
#plt.show()
#
#sns.barplot(bins[:-1], freq)
#
#
#
## weighted in how foten it appears in the data
#df = pd.read_csv(soccer_output + 'soccer_prepared.csv', sep=';')
#df = df.merge(stadium_monitor, on='stadium')
#
#sns.distplot(df['distance_closest_sdo'], hist=True, kde=False, norm_hist=True,
#             bins=int(50/4), color = 'darkblue',
#             hist_kws={'edgecolor':'black'})
#
#plt.title('Histogram of Distances from weather monitor to stadiums')
#plt.xlabel('Distance (km)')
#plt.ylabel('Number of monitor-stadium pairs')

